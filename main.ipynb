{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextToSQLDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.text = [d['text'] for d in data]\n",
    "        self.sql = [d['sql'] for d in data]\n",
    "        # Define tokenizer and vocab\n",
    "        self.tokenizer = ...\n",
    "        self.vocab = ...\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Tokenize text and SQL\n",
    "        text_tokens = self.tokenizer.tokenize(self.text[idx])\n",
    "        sql_tokens = self.tokenizer.tokenize(self.sql[idx])\n",
    "        # Convert tokens to IDs\n",
    "        text_ids = [self.vocab.get_id(token) for token in text_tokens]\n",
    "        sql_ids = [self.vocab.get_id(token) for token in sql_tokens]\n",
    "        return {'text_ids': text_ids, 'sql_ids': sql_ids}\n",
    "\n",
    "class TextToSQLModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextToSQLModel, self).__init__()\n",
    "        # Define embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
    "        # Define encoder LSTM\n",
    "        self.encoder = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "        # Define decoder LSTM\n",
    "        self.decoder = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "        # Define attention mechanism\n",
    "        self.attention = nn.MultiheadAttention(hidden_size, num_heads=8)\n",
    "        # Define output layer\n",
    "        self.output_layer = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, text_ids, sql_ids):\n",
    "        # Encode input sequence\n",
    "        embedded = self.embedding(text_ids)\n",
    "        encoded_sequence, (encoded_h, encoded_c) = self.encoder(embedded)\n",
    "        # Decode encoded sequence\n",
    "        decoded_sequence, _ = self.decoder(self.embedding(sql_ids), (encoded_h, encoded_c))\n",
    "        # Attend to encoded sequence\n",
    "        attended_sequence, _ = self.attention(query=decoded_sequence.transpose(0, 1), key=encoded_sequence.transpose(0, 1), value=encoded_sequence.transpose(0, 1))\n",
    "        # Predict SQL query from attended sequence\n",
    "        sql_output = self.output_layer(attended_sequence.transpose(0, 1))\n",
    "        return sql_output\n",
    "\n",
    "# Define hyperparameters\n",
    "vocab_size = ...\n",
    "embedding_size = ...\n",
    "hidden_size = ...\n",
    "batch_size = ...\n",
    "learning_rate = ...\n",
    "num_epochs = ...\n",
    "\n",
    "# Define dataset and data loader\n",
    "train_data = ...\n",
    "train_dataset = TextToSQLDataset(train_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define model and optimizer\n",
    "model = TextToSQLModel(vocab_size, embedding_size, hidden_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        # Move batch to GPU if available\n",
    "        text_ids = batch['text_ids'].to(device)\n",
    "        sql_ids = batch['sql_ids'].to(device)\n",
    "        # Compute loss and backpropagate\n",
    "        optimizer.zero_grad()\n",
    "        sql_output = model(text_ids, sql_ids[:, :-1])\n",
    "        loss = F.cross_entropy(sql_output.transpose(1, 2), sql_ids[:, 1:])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print loss every 100 batches\n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Batch {i}, Loss {loss.item()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
