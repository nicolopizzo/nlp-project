{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikisql (/home/nicolopizzo/.cache/huggingface/datasets/wikisql/default/0.1.0/7037bfe6a42b1ca2b6ac3ccacba5253b1825d31379e9cc626fc79a620977252d)\n"
     ]
    }
   ],
   "source": [
    "generated_queries = pd.read_csv(\"test_resources/generated_queries.csv\")\n",
    "\n",
    "test_dataset = load_dataset(\"wikisql\", split='test')\n",
    "test_queries = test_dataset['question']\n",
    "test_target = [row['human_readable'] for row in test_dataset['sql']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "agg_ops = ['MAX', 'MIN', 'COUNT', 'SUM', 'AVG']\n",
    "cond_ops = ['=', '>', '<', 'OP']\n",
    "\n",
    "\n",
    "# idx = 92\n",
    "# header = test_dataset[idx]['table']['header']\n",
    "# tid = test_dataset[idx]['table']['id']\n",
    "# query = test_dataset[idx]['sql']['human_readable']\n",
    "\n",
    "def get_agg(sel_clause: str) -> str:\n",
    "    for agg in agg_ops:\n",
    "        if agg in sel_clause:\n",
    "            return agg\n",
    "    \n",
    "    return None\n",
    "\n",
    "def extract_column(sel_clause: str) -> str:\n",
    "    agg = get_agg(sel_clause)\n",
    "    if agg != None:\n",
    "        index = sel_clause.index(agg) + len(agg)\n",
    "    else:\n",
    "        index = len('SELECT')\n",
    "    \n",
    "    return sel_clause[index:].strip()\n",
    "\n",
    "def extract_clauses(where_clause: str, col_mapping: dict[str, str]) -> str:\n",
    "    conditions = [c.strip() for c in where_clause.split(' AND ')]\n",
    "    clauses = []\n",
    "    for c in conditions:\n",
    "        splitted = re.split(' ([=><]|OP) ', c)\n",
    "        if len(splitted) > 3:\n",
    "            splitted[2] = ''.join(splitted[2:])\n",
    "            splitted = splitted[:3]\n",
    "        elif len(splitted) < 3:\n",
    "            pass\n",
    "            # print(splitted)\n",
    "            # print(where_clause)\n",
    "        [col, op, value] = splitted\n",
    "        value = value.strip()\n",
    "        col = col.strip()\n",
    "        \n",
    "        col = col_mapping.get(col)\n",
    "        num_regex = r'^\\d+[.\\d+]?$'\n",
    "        value = value.replace('\"', '')\n",
    "        if (not re.match(num_regex, value)) or (not '\"' in value): \n",
    "            value = f'\"{value.lower()}\"'\n",
    "        clauses.append(f'{col}{op}{value}')\n",
    "    \n",
    "    return 'WHERE ' + ' AND '.join(clauses)    \n",
    "    \n",
    "\n",
    "def fix_query(query: str, header: str, tid: str) -> str:\n",
    "    # FIX SELECT [AGG] CLAUSE\n",
    "    from_index = query.index(\"FROM\")\n",
    "    \n",
    "    col_mapping = { col: f'col{i}' for i, col in enumerate(header)}\n",
    "    \n",
    "    select_clause = query[:from_index]\n",
    "    col_name = extract_column(select_clause)\n",
    "    col = col_mapping.get(col_name)\n",
    "    agg = get_agg(select_clause)\n",
    "    if agg != None:\n",
    "        select = f\"SELECT {agg}({col})\"\n",
    "    else:\n",
    "        select = f\"SELECT {col}\"\n",
    "        \n",
    "    # FIX TABLE NAME\n",
    "    from_clause = f'FROM table_{tid.replace(\"-\", \"_\")}'\n",
    "    \n",
    "    # FIX WHERE CLAUSE\n",
    "    where = ''\n",
    "    if 'WHERE' in query:\n",
    "        where_index = query.index('WHERE')\n",
    "        where_clause = query[where_index + 5:]\n",
    "        where = extract_clauses(where_clause, col_mapping)\n",
    "    \n",
    "    return f'{select} AS result {from_clause} {where}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2787504723516816"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def logical_accuracy(test_queries: list[str], predicted_queries: list[str]) -> int:\n",
    "  # assert len(test_queries) == len(predicted_queries)\n",
    "\n",
    "  count = 0\n",
    "  for tq, pq in zip(test_queries, predicted_queries):\n",
    "    if tq.lower() == pq.lower():\n",
    "      count += 1\n",
    "\n",
    "  return count / len(test_queries)\n",
    "\n",
    "predicted_queries = generated_queries['query'].tolist().copy()\n",
    "logical_accuracy(test_target, predicted_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors encountered: 8238\n",
      "Queries with valid syntax: 7640\n",
      "Correct Queries with valid syntax: 4770\n",
      "Incorrect Queries with valid syntax: 2870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3004156694797833"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3 as sql\n",
    "from sqlite3 import Error\n",
    "import copy\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def execution_accuracy(test_queries: Dataset, predicted_queries: list[str], cursor: sql.Cursor) -> int:\n",
    "  assert len(test_queries) == len(predicted_queries)\n",
    "\n",
    "  count = 0\n",
    "  error = 0\n",
    "  for i, row in enumerate(test_queries):\n",
    "    header = row['table']['header']\n",
    "    tid = row['table']['id']\n",
    "    query = row['sql']['human_readable']\n",
    "    \n",
    "    tq = fix_query(query, header, tid)\n",
    "    cursor.execute(tq)\n",
    "    test_rows = cursor.fetchall()\n",
    "\n",
    "    try:\n",
    "      pq = fix_query(predicted_queries[i], header, tid)\n",
    "      cursor.execute(pq)\n",
    "      pred_rows = cursor.fetchall()\n",
    "    except:\n",
    "      pred_rows = None\n",
    "      error += 1\n",
    "    \n",
    "    count += (pred_rows == test_rows)\n",
    "\n",
    "  print(f\"Errors encountered: {error}\")\n",
    "  \n",
    "  n_q = len(test_queries)\n",
    "  \n",
    "  print(f\"Queries with valid syntax: {n_q - error}\")\n",
    "  print(f\"Correct Queries with valid syntax: {count}\")\n",
    "  print(f\"Incorrect Queries with valid syntax: {n_q - error - count}\")\n",
    "  return count / len(test_queries)\n",
    "\n",
    "def create_connection(db_file: str) -> sql.Connection:\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sql.connect(db_file)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "    return conn\n",
    "\n",
    "db_path = \"test_resources/test.db\"\n",
    "connection = create_connection(db_path)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "execution_accuracy(test_dataset, predicted_queries, cursor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
